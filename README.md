# PKRâ€‘Regression

Ultraâ€‘light, transparent and noiseâ€‘proof regression library

---
## ðŸš€ Why PKRâ€‘Regression?
| Pain Point | Classic ML | **PKR** |
|------------|-----------|---------|
| Hyperâ€‘parameters | âŒ Yes | âœ… No (3â€‘4 flags) |
| Blackâ€‘box outputs | âŒ Yes | âœ… Ruleâ€‘based explanation |
| Sensitive to noise | âŒ | âœ… Middle zone muted by median |
| Training time | Long / tuning | Seconds |

In short: *â€œKeep the crystalâ€‘clear signal, ignore the rest.â€*

---
## ðŸ” 4â€‘Step Method
1. **Pole Labeling**  
   Sort target *y*.  
   * Bottom 33â€¯% â†’ label `0`  
   * Top 33â€¯%   â†’ label `1`  
2. **Cell Scanning**  
   Build tiny cells for every 1â€‘, 2â€‘, 3â€‘feature combo (fixed width / exact category).  
3. **Valuable Kernel Selection**  
   * â‰¥â€¯90â€¯% same label  
   * â‰¥â€¯10 rows  
   â‡’ kernel value = mean of that cell.  
4. **Prediction**  
   * Test row hits â‰¥1 valuable kernel â†’ average(kernel_values)  
   * Hits none â†’ global median.

> Optional flags: `--bins 5` (five quantiles), `--max-dim 1/2/3`, `--gpu` for fast parallel scan.

---
## âš¡ Quick Start
```bash
pip install pkr-regression

pkr \
  --train train.csv \
  --test  test.csv \
  --target Listening_Time_minutes \
  --output submission.csv
```
Outputs: `submission.csv` (Kaggleâ€‘ready) + `kernels.txt` (selected cells)

---
## ðŸ“Š Kernel Example
| Kernel Rule | Prediction |
|-------------|-----------|
| Podcast = *Comedy Corner* & Length 0â€‘0.5 | **6.4 min** |
| Podcast = *Innovators* & Length 0.5â€‘1.0 | **91.7 min** |

A test row intersecting the first rule returns **6.4**; the second rule â†’ **91.7**.

---
## ðŸ’¡ FAQ
**Q:** Overfitting risk?  
**A:** No â€“ noisy cells (<â€¯90â€¯% majority or <â€¯10 rows) are discarded automatically.

**Q:** Big data?  
**A:** 1M+ rows train in minutes on one core; `--gpu` accelerates further.

---
Make your model **explainable** with PKRâ€‘Regression â€” try it & share feedback!


